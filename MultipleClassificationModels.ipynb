{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "  \n",
    "    \n",
    "#import all classifiers!\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153.4625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch      Fare  Embarked_C  \\\n",
       "0         0       3    1  19.0      0      0    7.6500           0   \n",
       "1         0       1    1  38.0      0      1  153.4625           0   \n",
       "2         0       3    1  17.0      0      0    8.6625           0   \n",
       "3         0       1    1  62.0      0      0   26.5500           0   \n",
       "4         1       1    0  23.0      3      2  263.0000           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           1  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv('titanic_processed.csv')\n",
    "\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Fare',\n",
       " 'Embarked_C',\n",
       " 'Embarked_Q',\n",
       " 'Embarked_S']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list all of features, from column 1(index start at 0) all the way to end\n",
    "FEATURES = list(titanic_df.columns[1:])\n",
    "\n",
    "FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict to store every Acc,precision,Recall for every classifier to later comparison\n",
    "result_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to return all our matrics\n",
    "\n",
    "def summarize_classification(y_test, y_pred):\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
    "    #normalize = true, will output as a fraction\n",
    "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
    "    #normalize = false will output the number of accurately predicted labels\n",
    "\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    #intuitively the ability of the classifier not to label as positive a sample that is negative\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    #intuitively the ability of the classifier to find all the positive samples\n",
    "    \n",
    "    return {'accuracy': acc, \n",
    "            'precision': prec,\n",
    "            'recall':recall, \n",
    "            'accuracy_count':num_acc}\n",
    "# all results will back in a dict format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to fit the classifier passing the following arguments:\n",
    "# classifier_fn : the name of classifier\n",
    "# name_of_y_col: the target column\n",
    "# names_of_x_cols: the features columns\n",
    "#dataset : the dateset\n",
    "# test_frac : split percentage of testing\n",
    "\n",
    "#the function will evaluate the model performance on the training data\n",
    "def build_model(classifier_fn,                \n",
    "                name_of_y_col, \n",
    "                names_of_x_cols, \n",
    "                dataset, \n",
    "                test_frac=0.2):\n",
    "    \n",
    "    X = dataset[names_of_x_cols]\n",
    "    Y = dataset[name_of_y_col]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_frac)\n",
    "       \n",
    "    model = classifier_fn(x_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    \n",
    "    #summarize_classification is a function defined earlier\n",
    "    train_summary = summarize_classification(y_train, y_pred_train)\n",
    "    test_summary = summarize_classification(y_test, y_pred)\n",
    "    \n",
    "    pred_results = pd.DataFrame({'y_test': y_test,\n",
    "                                 'y_pred': y_pred})\n",
    "    \n",
    "    model_crosstab = pd.crosstab(pred_results.y_pred, pred_results.y_test)\n",
    "    \n",
    "    \n",
    "    return {'training': train_summary, \n",
    "            'test': test_summary,\n",
    "            'confusion_matrix': model_crosstab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will print a report by accessing every key the dict and print training-score, test-score\n",
    "def compare_results():\n",
    "    for key in result_dict:\n",
    "        print('Classification: ', key)\n",
    "\n",
    "        print()\n",
    "        print('Training data')\n",
    "        for score in result_dict[key]['training']:\n",
    "            print(score, result_dict[key]['training'][score])\n",
    "\n",
    "        print()\n",
    "        print('Test data')\n",
    "        for score in result_dict[key]['test']:\n",
    "            print(score, result_dict[key]['test'][score])\n",
    "       \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate a logistic regression estimator\n",
    "def logistic_fn(x_train, y_train):\n",
    "    \n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification:  survived ~ logistic\n",
      "\n",
      "Training data\n",
      "accuracy 0.7908611599297012\n",
      "precision 0.7688679245283019\n",
      "recall 0.6995708154506438\n",
      "accuracy_count 450\n",
      "\n",
      "Test data\n",
      "accuracy 0.8041958041958042\n",
      "precision 0.7755102040816326\n",
      "recall 0.6909090909090909\n",
      "accuracy_count 115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict['survived ~ logistic'] = build_model(logistic_fn,\n",
    "                                              'Survived',\n",
    "                                               FEATURES,\n",
    "                                               titanic_df)\n",
    "\n",
    "compare_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA assumed the ys corresponding to xs have the same covariant matrix, lets initiate:\n",
    "#SVD(default):singular value decomposition to calculate the axes to seperate our data without calculating the covariance matrix of feature\n",
    "#be aware of \"dummy trap\", if you encountered collinearity problem because of hot-encode, try dropping one column of your hot-encoding columns to turn it into dummy-encoded\n",
    "def linear_discriminant_fn(x_train, y_train, solver='svd'):\n",
    "    \n",
    "    model = LinearDiscriminantAnalysis(solver=solver)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification:  survived ~ logistic\n",
      "\n",
      "Training data\n",
      "accuracy 0.7908611599297012\n",
      "precision 0.7688679245283019\n",
      "recall 0.6995708154506438\n",
      "accuracy_count 450\n",
      "\n",
      "Test data\n",
      "accuracy 0.8041958041958042\n",
      "precision 0.7755102040816326\n",
      "recall 0.6909090909090909\n",
      "accuracy_count 115\n",
      "\n",
      "Classification:  survived ~ linear_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.8014059753954306\n",
      "precision 0.7819905213270142\n",
      "recall 0.7112068965517241\n",
      "accuracy_count 456\n",
      "\n",
      "Test data\n",
      "accuracy 0.7622377622377622\n",
      "precision 0.7115384615384616\n",
      "recall 0.6607142857142857\n",
      "accuracy_count 109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict['survived ~ linear_discriminant_analysis'] = build_model(linear_discriminant_fn,\n",
    "                                                                 'Survived',\n",
    "                                                                  FEATURES,\n",
    "                                                                  titanic_df)\n",
    "compare_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification:  survived ~ logistic\n",
      "\n",
      "Training data\n",
      "accuracy 0.7908611599297012\n",
      "precision 0.7688679245283019\n",
      "recall 0.6995708154506438\n",
      "accuracy_count 450\n",
      "\n",
      "Test data\n",
      "accuracy 0.8041958041958042\n",
      "precision 0.7755102040816326\n",
      "recall 0.6909090909090909\n",
      "accuracy_count 115\n",
      "\n",
      "Classification:  survived ~ linear_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.8031634446397188\n",
      "precision 0.7707317073170732\n",
      "recall 0.7085201793721974\n",
      "accuracy_count 457\n",
      "\n",
      "Test data\n",
      "accuracy 0.7902097902097902\n",
      "precision 0.8431372549019608\n",
      "recall 0.6615384615384615\n",
      "accuracy_count 113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lets test by excluding one hot-encoding column and turn it into dummy-encoded to the see if the model accounted for collinearity.\n",
    "result_dict['survived ~ linear_discriminant_analysis'] = build_model(linear_discriminant_fn,\n",
    "                                                                     'Survived',\n",
    "                                                                      FEATURES[0:-1],\n",
    "                                                                      titanic_df)\n",
    "compare_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QDA: lets try QDA if our data have a different covariance matrix for Xs variables to different Ys\n",
    "\n",
    "def quadratic_discriminant_fn(x_train, y_train):\n",
    "    \n",
    "    model = QuadraticDiscriminantAnalysis()\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification:  survived ~ logistic\n",
      "\n",
      "Training data\n",
      "accuracy 0.7908611599297012\n",
      "precision 0.7688679245283019\n",
      "recall 0.6995708154506438\n",
      "accuracy_count 450\n",
      "\n",
      "Test data\n",
      "accuracy 0.8041958041958042\n",
      "precision 0.7755102040816326\n",
      "recall 0.6909090909090909\n",
      "accuracy_count 115\n",
      "\n",
      "Classification:  survived ~ linear_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.8031634446397188\n",
      "precision 0.7707317073170732\n",
      "recall 0.7085201793721974\n",
      "accuracy_count 457\n",
      "\n",
      "Test data\n",
      "accuracy 0.7902097902097902\n",
      "precision 0.8431372549019608\n",
      "recall 0.6615384615384615\n",
      "accuracy_count 113\n",
      "\n",
      "Classification:  survived ~ quadratic_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.7926186291739895\n",
      "precision 0.7804878048780488\n",
      "recall 0.6866952789699571\n",
      "accuracy_count 451\n",
      "\n",
      "Test data\n",
      "accuracy 0.7972027972027972\n",
      "precision 0.7241379310344828\n",
      "recall 0.7636363636363637\n",
      "accuracy_count 114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#again we will use dummy-encoded instead of hot-encoding\n",
    "result_dict['survived ~ quadratic_discriminant_analysis'] = build_model(quadratic_discriminant_fn,\n",
    "                                                                        'Survived',\n",
    "                                                                        FEATURES[0:-1],\n",
    "                                                                        titanic_df)\n",
    "\n",
    "compare_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic gradient descent\n",
    "#Warning, before moving on to another classifier change the iteration, because performance could depends on it!\n",
    "def sgd_fn(x_train, y_train, max_iter=10000, tol=1e-3):\n",
    "    \n",
    "    model = SGDClassifier(max_iter=max_iter, tol=tol)\n",
    "    model.fit(x_train, y_train)\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification:  survived ~ logistic\n",
      "\n",
      "Training data\n",
      "accuracy 0.7908611599297012\n",
      "precision 0.7688679245283019\n",
      "recall 0.6995708154506438\n",
      "accuracy_count 450\n",
      "\n",
      "Test data\n",
      "accuracy 0.8041958041958042\n",
      "precision 0.7755102040816326\n",
      "recall 0.6909090909090909\n",
      "accuracy_count 115\n",
      "\n",
      "Classification:  survived ~ linear_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.8031634446397188\n",
      "precision 0.7707317073170732\n",
      "recall 0.7085201793721974\n",
      "accuracy_count 457\n",
      "\n",
      "Test data\n",
      "accuracy 0.7902097902097902\n",
      "precision 0.8431372549019608\n",
      "recall 0.6615384615384615\n",
      "accuracy_count 113\n",
      "\n",
      "Classification:  survived ~ quadratic_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.7926186291739895\n",
      "precision 0.7804878048780488\n",
      "recall 0.6866952789699571\n",
      "accuracy_count 451\n",
      "\n",
      "Test data\n",
      "accuracy 0.7972027972027972\n",
      "precision 0.7241379310344828\n",
      "recall 0.7636363636363637\n",
      "accuracy_count 114\n",
      "\n",
      "Classification:  survived ~ sgd\n",
      "\n",
      "Training data\n",
      "accuracy 0.4727592267135325\n",
      "precision 0.426\n",
      "recall 0.9424778761061947\n",
      "accuracy_count 269\n",
      "\n",
      "Test data\n",
      "accuracy 0.5664335664335665\n",
      "precision 0.5\n",
      "recall 0.9838709677419355\n",
      "accuracy_count 81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict['survived ~ sgd'] = build_model(sgd_fn,\n",
    "                                           'Survived',\n",
    "                                            FEATURES,\n",
    "                                            titanic_df)\n",
    "\n",
    "compare_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM find the hyperplane that best seperate between the targeted point, either directly or transforming into higher-plane\n",
    "#We will use SVM classifier, C=1.0 will penalize the points on the wrong side of the seprator, small values mean stron regularization\n",
    "# those two functions are equivalent LinearSVC == SVC(kernel='linear')\n",
    "# Dual=False (prefered, when N_samples>P_predictors) not transforming primal problem to dual problem\n",
    "def linear_svc_fn(x_train, y_train, C=1.0, max_iter=1000, tol=1e-3):\n",
    "    \n",
    "    model = LinearSVC(C=C, max_iter=max_iter, tol=tol, dual=False)\n",
    "    model.fit(x_train, y_train) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification:  survived ~ logistic\n",
      "\n",
      "Training data\n",
      "accuracy 0.7908611599297012\n",
      "precision 0.7688679245283019\n",
      "recall 0.6995708154506438\n",
      "accuracy_count 450\n",
      "\n",
      "Test data\n",
      "accuracy 0.8041958041958042\n",
      "precision 0.7755102040816326\n",
      "recall 0.6909090909090909\n",
      "accuracy_count 115\n",
      "\n",
      "Classification:  survived ~ linear_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.8031634446397188\n",
      "precision 0.7707317073170732\n",
      "recall 0.7085201793721974\n",
      "accuracy_count 457\n",
      "\n",
      "Test data\n",
      "accuracy 0.7902097902097902\n",
      "precision 0.8431372549019608\n",
      "recall 0.6615384615384615\n",
      "accuracy_count 113\n",
      "\n",
      "Classification:  survived ~ quadratic_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.7926186291739895\n",
      "precision 0.7804878048780488\n",
      "recall 0.6866952789699571\n",
      "accuracy_count 451\n",
      "\n",
      "Test data\n",
      "accuracy 0.7972027972027972\n",
      "precision 0.7241379310344828\n",
      "recall 0.7636363636363637\n",
      "accuracy_count 114\n",
      "\n",
      "Classification:  survived ~ sgd\n",
      "\n",
      "Training data\n",
      "accuracy 0.4727592267135325\n",
      "precision 0.426\n",
      "recall 0.9424778761061947\n",
      "accuracy_count 269\n",
      "\n",
      "Test data\n",
      "accuracy 0.5664335664335665\n",
      "precision 0.5\n",
      "recall 0.9838709677419355\n",
      "accuracy_count 81\n",
      "\n",
      "Classification:  survived ~ linear_svc\n",
      "\n",
      "Training data\n",
      "accuracy 0.8014059753954306\n",
      "precision 0.7962085308056872\n",
      "recall 0.7058823529411765\n",
      "accuracy_count 456\n",
      "\n",
      "Test data\n",
      "accuracy 0.7902097902097902\n",
      "precision 0.6851851851851852\n",
      "recall 0.74\n",
      "accuracy_count 113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict['survived ~ linear_svc'] = build_model(linear_svc_fn,\n",
    "                                                  'Survived',\n",
    "                                                   FEATURES,\n",
    "                                                   titanic_df)\n",
    "\n",
    "compare_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nearest_Neighbor classify based on the nearest distance between sample points, whether Euclidean, Hamming, Manhattan\n",
    "#we will use Radius_Neighbor instead of K_Neighbor for more robust results\n",
    "#change the radius and check different results\n",
    "def radius_neighbor_fn(x_train, y_train, radius=40.0):\n",
    "\n",
    "    model = RadiusNeighborsClassifier(radius=radius)\n",
    "    model.fit(x_train, y_train) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification:  survived ~ logistic\n",
      "\n",
      "Training data\n",
      "accuracy 0.7908611599297012\n",
      "precision 0.7688679245283019\n",
      "recall 0.6995708154506438\n",
      "accuracy_count 450\n",
      "\n",
      "Test data\n",
      "accuracy 0.8041958041958042\n",
      "precision 0.7755102040816326\n",
      "recall 0.6909090909090909\n",
      "accuracy_count 115\n",
      "\n",
      "Classification:  survived ~ linear_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.8031634446397188\n",
      "precision 0.7707317073170732\n",
      "recall 0.7085201793721974\n",
      "accuracy_count 457\n",
      "\n",
      "Test data\n",
      "accuracy 0.7902097902097902\n",
      "precision 0.8431372549019608\n",
      "recall 0.6615384615384615\n",
      "accuracy_count 113\n",
      "\n",
      "Classification:  survived ~ quadratic_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.7926186291739895\n",
      "precision 0.7804878048780488\n",
      "recall 0.6866952789699571\n",
      "accuracy_count 451\n",
      "\n",
      "Test data\n",
      "accuracy 0.7972027972027972\n",
      "precision 0.7241379310344828\n",
      "recall 0.7636363636363637\n",
      "accuracy_count 114\n",
      "\n",
      "Classification:  survived ~ sgd\n",
      "\n",
      "Training data\n",
      "accuracy 0.4727592267135325\n",
      "precision 0.426\n",
      "recall 0.9424778761061947\n",
      "accuracy_count 269\n",
      "\n",
      "Test data\n",
      "accuracy 0.5664335664335665\n",
      "precision 0.5\n",
      "recall 0.9838709677419355\n",
      "accuracy_count 81\n",
      "\n",
      "Classification:  survived ~ linear_svc\n",
      "\n",
      "Training data\n",
      "accuracy 0.8014059753954306\n",
      "precision 0.7962085308056872\n",
      "recall 0.7058823529411765\n",
      "accuracy_count 456\n",
      "\n",
      "Test data\n",
      "accuracy 0.7902097902097902\n",
      "precision 0.6851851851851852\n",
      "recall 0.74\n",
      "accuracy_count 113\n",
      "\n",
      "Classification:  survived ~ radius_neighbors\n",
      "\n",
      "Training data\n",
      "accuracy 0.664323374340949\n",
      "precision 0.7254901960784313\n",
      "recall 0.31223628691983124\n",
      "accuracy_count 378\n",
      "\n",
      "Test data\n",
      "accuracy 0.7202797202797203\n",
      "precision 0.7391304347826086\n",
      "recall 0.3333333333333333\n",
      "accuracy_count 103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict['survived ~ radius_neighbors'] = build_model(radius_neighbor_fn,\n",
    "                                                         'Survived',\n",
    "                                                         FEATURES,\n",
    "                                                         titanic_df)\n",
    "compare_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use decision tree to split of P_predictors into subgroups of multiple decisions\n",
    "#we will not set any shape for the tree, max_depth=None, max_features=None. If the dataset is huge, set constraints, this model could easily overfit!\n",
    "def decision_tree_fn(x_train, y_train, max_depth=None, max_features=None): \n",
    "    \n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, max_features=max_features)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification:  survived ~ logistic\n",
      "\n",
      "Training data\n",
      "accuracy 0.7908611599297012\n",
      "precision 0.7688679245283019\n",
      "recall 0.6995708154506438\n",
      "accuracy_count 450\n",
      "\n",
      "Test data\n",
      "accuracy 0.8041958041958042\n",
      "precision 0.7755102040816326\n",
      "recall 0.6909090909090909\n",
      "accuracy_count 115\n",
      "\n",
      "Classification:  survived ~ linear_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.8031634446397188\n",
      "precision 0.7707317073170732\n",
      "recall 0.7085201793721974\n",
      "accuracy_count 457\n",
      "\n",
      "Test data\n",
      "accuracy 0.7902097902097902\n",
      "precision 0.8431372549019608\n",
      "recall 0.6615384615384615\n",
      "accuracy_count 113\n",
      "\n",
      "Classification:  survived ~ quadratic_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.7926186291739895\n",
      "precision 0.7804878048780488\n",
      "recall 0.6866952789699571\n",
      "accuracy_count 451\n",
      "\n",
      "Test data\n",
      "accuracy 0.7972027972027972\n",
      "precision 0.7241379310344828\n",
      "recall 0.7636363636363637\n",
      "accuracy_count 114\n",
      "\n",
      "Classification:  survived ~ sgd\n",
      "\n",
      "Training data\n",
      "accuracy 0.4727592267135325\n",
      "precision 0.426\n",
      "recall 0.9424778761061947\n",
      "accuracy_count 269\n",
      "\n",
      "Test data\n",
      "accuracy 0.5664335664335665\n",
      "precision 0.5\n",
      "recall 0.9838709677419355\n",
      "accuracy_count 81\n",
      "\n",
      "Classification:  survived ~ linear_svc\n",
      "\n",
      "Training data\n",
      "accuracy 0.8014059753954306\n",
      "precision 0.7962085308056872\n",
      "recall 0.7058823529411765\n",
      "accuracy_count 456\n",
      "\n",
      "Test data\n",
      "accuracy 0.7902097902097902\n",
      "precision 0.6851851851851852\n",
      "recall 0.74\n",
      "accuracy_count 113\n",
      "\n",
      "Classification:  survived ~ radius_neighbors\n",
      "\n",
      "Training data\n",
      "accuracy 0.664323374340949\n",
      "precision 0.7254901960784313\n",
      "recall 0.31223628691983124\n",
      "accuracy_count 378\n",
      "\n",
      "Test data\n",
      "accuracy 0.7202797202797203\n",
      "precision 0.7391304347826086\n",
      "recall 0.3333333333333333\n",
      "accuracy_count 103\n",
      "\n",
      "Classification:  survived ~ decision_tree\n",
      "\n",
      "Training data\n",
      "accuracy 0.984182776801406\n",
      "precision 1.0\n",
      "recall 0.9608695652173913\n",
      "accuracy_count 560\n",
      "\n",
      "Test data\n",
      "accuracy 0.7692307692307693\n",
      "precision 0.7358490566037735\n",
      "recall 0.6724137931034483\n",
      "accuracy_count 110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict['survived ~ decision_tree'] = build_model(decision_tree_fn,\n",
    "                                                 'Survived',\n",
    "                                                  FEATURES,\n",
    "                                                  titanic_df)\n",
    "\n",
    "compare_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive will use Bayes theorem to find which lable is high probable give the attributes in the feature vector\n",
    "#you can pass priors if you know any priors about your features.\n",
    "def naive_bayes_fn(x_train,y_train, priors=None):\n",
    "    \n",
    "    model = GaussianNB(priors=priors)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification:  survived ~ logistic\n",
      "\n",
      "Training data\n",
      "accuracy 0.7908611599297012\n",
      "precision 0.7688679245283019\n",
      "recall 0.6995708154506438\n",
      "accuracy_count 450\n",
      "\n",
      "Test data\n",
      "accuracy 0.8041958041958042\n",
      "precision 0.7755102040816326\n",
      "recall 0.6909090909090909\n",
      "accuracy_count 115\n",
      "\n",
      "Classification:  survived ~ linear_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.8031634446397188\n",
      "precision 0.7707317073170732\n",
      "recall 0.7085201793721974\n",
      "accuracy_count 457\n",
      "\n",
      "Test data\n",
      "accuracy 0.7902097902097902\n",
      "precision 0.8431372549019608\n",
      "recall 0.6615384615384615\n",
      "accuracy_count 113\n",
      "\n",
      "Classification:  survived ~ quadratic_discriminant_analysis\n",
      "\n",
      "Training data\n",
      "accuracy 0.7926186291739895\n",
      "precision 0.7804878048780488\n",
      "recall 0.6866952789699571\n",
      "accuracy_count 451\n",
      "\n",
      "Test data\n",
      "accuracy 0.7972027972027972\n",
      "precision 0.7241379310344828\n",
      "recall 0.7636363636363637\n",
      "accuracy_count 114\n",
      "\n",
      "Classification:  survived ~ sgd\n",
      "\n",
      "Training data\n",
      "accuracy 0.4727592267135325\n",
      "precision 0.426\n",
      "recall 0.9424778761061947\n",
      "accuracy_count 269\n",
      "\n",
      "Test data\n",
      "accuracy 0.5664335664335665\n",
      "precision 0.5\n",
      "recall 0.9838709677419355\n",
      "accuracy_count 81\n",
      "\n",
      "Classification:  survived ~ linear_svc\n",
      "\n",
      "Training data\n",
      "accuracy 0.8014059753954306\n",
      "precision 0.7962085308056872\n",
      "recall 0.7058823529411765\n",
      "accuracy_count 456\n",
      "\n",
      "Test data\n",
      "accuracy 0.7902097902097902\n",
      "precision 0.6851851851851852\n",
      "recall 0.74\n",
      "accuracy_count 113\n",
      "\n",
      "Classification:  survived ~ radius_neighbors\n",
      "\n",
      "Training data\n",
      "accuracy 0.664323374340949\n",
      "precision 0.7254901960784313\n",
      "recall 0.31223628691983124\n",
      "accuracy_count 378\n",
      "\n",
      "Test data\n",
      "accuracy 0.7202797202797203\n",
      "precision 0.7391304347826086\n",
      "recall 0.3333333333333333\n",
      "accuracy_count 103\n",
      "\n",
      "Classification:  survived ~ decision_tree\n",
      "\n",
      "Training data\n",
      "accuracy 0.984182776801406\n",
      "precision 1.0\n",
      "recall 0.9608695652173913\n",
      "accuracy_count 560\n",
      "\n",
      "Test data\n",
      "accuracy 0.7692307692307693\n",
      "precision 0.7358490566037735\n",
      "recall 0.6724137931034483\n",
      "accuracy_count 110\n",
      "\n",
      "Classification:  survived ~ naive_bayes\n",
      "\n",
      "Training data\n",
      "accuracy 0.7662565905096661\n",
      "precision 0.7066115702479339\n",
      "recall 0.7339055793991416\n",
      "accuracy_count 436\n",
      "\n",
      "Test data\n",
      "accuracy 0.7622377622377622\n",
      "precision 0.6842105263157895\n",
      "recall 0.7090909090909091\n",
      "accuracy_count 109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict['survived ~ naive_bayes'] = build_model(naive_bayes_fn,\n",
    "                                                    'Survived',\n",
    "                                                    FEATURES,\n",
    "                                                    titanic_df)\n",
    "\n",
    "compare_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
